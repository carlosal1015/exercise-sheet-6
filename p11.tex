\section{Pregunta N$^{\circ}$11\qquad Alejandro Escobar Mejia}

\begin{frame}
	\frametitle{
		Cálculo de la inversa de una matriz grande
		$A\in\mathbb{R}^{n\times n}$
	}

	Es una tarea desafiante porque usando la fórmula
	\begin{math}
		\det\left(A\right)=
		\sum_{\sigma}
		\operatorname{sign}\left(\sigma\right)
		a_{1\sigma\left(1\right)}
		\cdots
		a_{n\sigma\left(n\right)}
	\end{math}
	podría requerir $O\left(\left(n-1\right)n!\right)$
	multiplicaciones.
	El algoritmo de eliminación gaussiana permite transformar una
	matriz en forma triangular con $O\left(n^{3}\right)$ operaciones.
	Además, este algoritmo incluye divisiones por entradas de la
	matriz, lo que requiere una estrategia de pivote para evitar
	inestabilidades numéricas.
	Es más, este algoritmo no se puede utilizar sobre matrices que
	tiene entradas sobre un anillo conmutativo sin división.
	Por lo tanto, es deseable encontrar un algoritmo rápido sin
	divisiones.
	El algoritmo clásico de \alert{Faddeev-LeVerrier} proporciona
	precisamente esto, su complejidad computacional es del orden
	$O\left(n^{\beta+1}\right)$ y evita cualquier división por una
	entrada de la matriz.
	Aquí $O\left(n^{\beta}\right)$ es el costo computacional de
	multiplicar dos matrices $n\times n$.
	El valor preciso de $\beta$ es desconocido, pero está en el
	intervalo $\left[2,2.37286\right[$. Este enfoque consiste en
	\begin{equation*}
		B_{0}=I_{n},\quad
		\alpha_{k}=
		\dfrac{1}{k}
		\operatorname{tr}\left(AB_{k-1}\right),\quad
		B_{k}=-AB_{k-1}+\alpha_{k},\quad
		\forall k\in\mathbb{N}.
	\end{equation*}

	% \begin{block}{Derivación del algoritmo}
	% 	\begin{equation*}
	% 		\chi\left(t\right)\coloneqq
	% 		\sum\limits_{j=0}^{n}
	% 		c_{n-j}t^{j}
	% 	\end{equation*}
	% \end{block}
\end{frame}

% \begin{frame}
% 	Sea $A\in\mathbb{R}^{n\times n}$ una matriz y su polinomio
% 	característico es
% 	\begin{equation*}
% 		a\left(\lambda\right)=
% 		\left(-1\right)^{n}
% 		\left[
% 		\lambda^{n}-a_{1}\lambda^{n-1}-\cdots-a_{n-1}\lambda-a_{n}
% 		\right],
% 	\end{equation*}
% 	donde $I_{n}$ denota la matriz identidad de orden $n$, y sea
% 	\begin{equation*}
% 		{\left(\lambda I_{n}-A\right)}^{n-1}=
% 		\dfrac{
% 		\lambda^{n-1}I_{n}+
% 		\lambda^{n-2}B_{1}+
% 		\cdots+
% 		\lambda B_{n-2}+
% 		B_{n-1}
% 		}{a\left(\lambda\right)}.
% 	\end{equation*}

% 	\begin{align*}
% 		a_{1} & =-\operatorname{tr}\left(A\right),                    &
% 		a_{k} & =-\dfrac{1}{k}\operatorname{tr}\left(AB_{k-1}\right),
% 		      & k\in\left\{2,\dotsc,n\right\}.                          \\
% 		B_{1} & = A + a_{1}I_{n},                                     &
% 		B_{k} & =AB_{k-1}+a_{k}I_{n},
% 		      & k\in\left\{2,\dotsc,n-1\right\}.
% 	\end{align*}
% 	donde $\operatorname{tr}\left(A\right)$ denota la traza de $A$.
% \end{frame}

% \begin{frame}
% 	\frametitle{Método de Krylov}

% 	\begin{theorem}[Caley-Hamilton]
% 		Suponga que $V$ un espacio vectorial complejo y
% 		$T\in\mathcal{L}\left(V\right)$.
% 		Sea $q$ el polinomio característico de $T$.
% 		Entonces, $q\left(T\right)=0$.
% 	\end{theorem}

% 	% https://apuntespme.cl/biblio/AXLER_LINEARALGEBRA.pdf
% 	% https://en.wikipedia.org/wiki/Cayley%E2%80%93Hamilton_theorem#Determinant_and_inverse_matrix
% 	\begin{theorem}
% 		Suponga que $T\in\mathcal{L}\left(V\right)$ y
% 		$q\in\mathcal{P}\left(\mathbb{R}\right)$.
% 		Entonces, $q\left(T\right)=0$ sii $q$ es un polinomio múltiplo
% 		del polinomio minimal de $T$.
% 	\end{theorem}

% 	\begin{block}{Observación}
% 		Sea $A\in\mathbb{R}^{n\times n}$ una matriz invertible
% 		\begin{equation*}
% 			p\left(A\right)=
% 			A^{n}+
% 			c_{n-1}A^{n-1}+
% 			\cdots+
% 			c_{1}A+
% 			{\left(-1\right)}^{n}
% 			\det\left(A\right)I_{n}=
% 			0.
% 		\end{equation*}
% 	\end{block}
% \end{frame}

\begin{frame}
	\begin{enumerate}\setcounter{enumi}{10}
		\item

		      Un territorio está dividido en dos zonas $Z_{1}$ y
		      $Z_{2}$ entre las que habita una población de aves.
		      Cada año y debido a diversas razones (disponibilidad de
		      alimentos, peleas por el territorio, etc.) se producen
		      las siguientes flujos migratorios entre las distintas
		      zonas.

		      \begin{columns}
			      \begin{column}{0.48\textwidth}
				      \begin{itemize}
					      \item

					            En $Z_{1}$: un $60$\% permanece en $Z_{1}$
					            y un $40$\% migra a $Z_{2}$.
				      \end{itemize}
			      \end{column}
			      \begin{column}{0.48\textwidth}
				      \begin{itemize}
					      \item

					            En $Z_{2}$: un $20$\% migra a $Z_{1}$ y un
					            $80$\% permanece en $Z_{2}$.
				      \end{itemize}
			      \end{column}
		      \end{columns}

		      Supongamos que tenemos una situación inicial en la que la
		      población total de aves un $60$\% viven en $Z_{1}$, un
		      $40$\% viven en $Z_{2}$.

		      \begin{enumerate}[a)]
			      \item

			            Indique las variables a usar.

			      \item

			            Determine la matriz que define la migración.

			      \item

			            Determine el polinomio característico usando los
			            métodos Leverrier y Krylov.

			      \item

			            Determine todos los valores y vectores propios
			            usando los métodos dados en clase.
		      \end{enumerate}
	\end{enumerate}

	\begin{solution}
		\begin{enumerate}[a)]
			\item

			      Sean $x_{1},x_{2}\in\mathbb{N}$ las variables que
			      representan la cantidad de aves en la zona $Z_{1}$ y
			      $Z_{2}$, respectivamente.

			\item

			      Sean $k$ la etapa actual y $k+1$ la etapa posterior.
			      Representamos la dinámica de población del territorio
			      como

			      \begin{equation*}
				      \begin{aligned}
					      x^{\left(k+1\right)}_{1} & =
					      \dfrac{3}{5}x^{\left(k\right)}_{1}+
					      \dfrac{1}{5}x_{2}^{\left(k\right)} \\
					      x^{\left(k+1\right)}_{2} & =
					      \dfrac{2}{5}x^{\left(k\right)}_{1}+
					      \dfrac{4}{5}x^{\left(k\right)}_{2}
				      \end{aligned}\iff
				      \underbrace{
					      \begin{bNiceMatrix}
						      x^{\left(k+1\right)}_{1} \\
						      x^{\left(k+1\right)}_{2}
					      \end{bNiceMatrix}
				      }_{\displaystyle x^{\left(k+1\right)}}
				      =
				      \underbrace{
					      \alert{
						      \begin{bNiceMatrix}
							      \dfrac{3}{5} & \dfrac{1}{5} \\
							      \dfrac{2}{5} & \dfrac{4}{5}
						      \end{bNiceMatrix}
					      }
				      }_{\displaystyle A}
				      \underbrace{
					      \begin{bNiceMatrix}
						      x^{\left(k\right)}_{1} \\
						      x^{\left(k\right)}_{2}
					      \end{bNiceMatrix}
				      }_{\displaystyle x^{\left(k\right)}},
			      \end{equation*}

			      donde $A$ es la matriz que define la migración de aves
			      entre las zonas $Z_{1}$ y $Z_{2}$.

			\item

			      Los coeficientes del polinomio característico de
			      $A\in\mathbb{R}^{2\times 2}$
			      \begin{math}
				      a\left(\lambda\right)=
				      \left(-1\right)^{2}
				      \left[\lambda^{2}-a_{1}\lambda-a_{2}\right]
			      \end{math}
			      se puede determinar a través del método de
			      Faddeev-LeVerrier y Krylov.
		\end{enumerate}
	\end{solution}
\end{frame}

\begin{frame}
	\begin{solution}
		\begin{enumerate}[c)]
			\item

			      \alert{Método de Faddeev-LeVerrier.} Si
			      \begin{math}
				      A=\begin{bNiceMatrix}
					      \dfrac{3}{5} & \dfrac{1}{5} \\
					      \dfrac{2}{5} & \dfrac{4}{5}
				      \end{bNiceMatrix}
			      \end{math}, entonces

			      \begin{align*}
				      B_{1}                            & \leftarrow
				      A=\begin{bNiceMatrix}
					        \dfrac{3}{5} & \dfrac{1}{5} \\
					        \dfrac{2}{5} & \dfrac{4}{5}
				        \end{bNiceMatrix}.   &
				      b_{1}                            & =
				      -\dfrac{\operatorname{tr}\left(B_{1}\right)}{1}=
				      -\frac{7}{5}.                                 \\
				      B_{2}                            & \leftarrow
				      A\left(B_{1}+b_{1}I_{2}\right)=
				      \begin{bNiceMatrix}
					      \dfrac{3}{5} & \dfrac{1}{5} \\
					      \dfrac{2}{5} & \dfrac{4}{5}
				      \end{bNiceMatrix}
				      \left(
				      \begin{bNiceMatrix}
					      \dfrac{3}{5} & \dfrac{1}{5} \\
					      \dfrac{2}{5} & \dfrac{4}{5}
				      \end{bNiceMatrix}-
				      \dfrac{7}{5}
				      \begin{bNiceMatrix}
					      1 & 0 \\
					      0 & 1
				      \end{bNiceMatrix}
				      \right)=
				      \begin{bNiceMatrix}
					      -\dfrac{2}{5} & 0             \\
					      0             & -\dfrac{2}{5}
				      \end{bNiceMatrix}. &
				      b_{2}                            & =
				      -\dfrac{\operatorname{tr}\left(B_{2}\right)}{2}=
				      \dfrac{2}{5}.
			      \end{align*}
			      Así, el polinomio característico de $A$ es
			      \begin{math}
				      a\left(\lambda\right)=
				      \lambda^{2}-a_{1}\lambda-a_{2}=
				      \lambda^{2}-\dfrac{7}{5}\lambda+\dfrac{2}{5}
			      \end{math}.

			      % \begin{equation*}
			      %   A^{2}=
			      %   \begin{bNiceMatrix}
			      %     0.44 & 0.28 \\
			      %     0.56 & 0.72
			      %   \end{bNiceMatrix},\quad
			      %   \begin{aligned}
			      %     s_{1} & =
			      %     \operatorname{tr}
			      %     \left(A\right)=
			      %     0.6+0.8=
			      %     1.4.      \\
			      %     s_{2} & =
			      %     \operatorname{tr}
			      %     \left(A^{2}\right)=
			      %     0.44+0.72=
			      %     1.16.     \\
			      %     a_{1} & =
			      %     -s_{1}=
			      %     -1.4.     \\
			      %     a_{2} & =
			      %     -\dfrac{1}{2}
			      %     \left(
			      %     s_{2}+
			      %     \left(a_{1}\times s_{1}\right)
			      %     \right)=
			      %     -\dfrac{1}{2}
			      %     \left(
			      %     1.16+
			      %     \left(-1.4\times 1.4\right)
			      %     \right)=
			      %     0.4.
			      %   \end{aligned}
			      % \end{equation*}

			      % Así,
			      % \begin{math}
			      %   P\left(x\right)=
			      %   x^{2}-1.4x+0.4
			      % \end{math}.
		\end{enumerate}
	\end{solution}
\end{frame}

\begin{frame}
	\begin{solution}
		\begin{enumerate}[c)]
			\item

			      \alert{Método de Krylov.} Si
			      \begin{math}
				      A=\begin{bNiceMatrix}
					      \dfrac{3}{5} & \dfrac{1}{5} \\
					      \dfrac{2}{5} & \dfrac{4}{5}
				      \end{bNiceMatrix}
			      \end{math} e
			      \begin{math}
				      y_{0}=
				      \begin{bNiceMatrix}
					      1 \\
					      0
				      \end{bNiceMatrix}
			      \end{math}
			      , entonces

			      \begin{equation*}
				      \begin{aligned}
					      y_{0} & =
					      \begin{bNiceMatrix}
						      1 \\
						      0
					      \end{bNiceMatrix}. \\
					      y_{1} & =
					      Ay_{0}=
					      \begin{bNiceMatrix}
						      0.6 \\
						      0.4
					      \end{bNiceMatrix}. \\
					      y_{2} & =
					      Ay_{1}=
					      \begin{bNiceMatrix}
						      0.44 \\
						      0.56
					      \end{bNiceMatrix}.
				      \end{aligned},\quad
				      \begin{aligned}
					      \begin{bNiceMatrix}
						      y_{1} & y_{0}
					      \end{bNiceMatrix}
					      \begin{bNiceMatrix}
						      a_{1} \\
						      a_{2}
					      \end{bNiceMatrix} & =
					      y_{2}.                \\
					      \begin{bNiceMatrix}
						      0.6 & 1 \\
						      0.4 & 0
					      \end{bNiceMatrix}
					      \begin{bNiceMatrix}
						      a_{1} \\
						      a_{2}
					      \end{bNiceMatrix} & =
					      \begin{bNiceMatrix}
						      0.44 \\
						      0.56
					      \end{bNiceMatrix}.    \\
					      \begin{bNiceMatrix}
						      a_{1} \\
						      a_{2}
					      \end{bNiceMatrix} & =
					      \begin{bNiceMatrix}
						      -1.4 \\
						      0.4
					      \end{bNiceMatrix}.
				      \end{aligned}
			      \end{equation*}

			      Así,
			      \begin{math}
				      P\left(x\right)=
				      x^{2}-1.4x+0.4
			      \end{math}.
		\end{enumerate}

		\begin{enumerate}[d)]
			\item

			      Método de Potencia
			      \begin{equation*}
				      A=
				      \begin{bNiceMatrix}
					      0.6 & 0.2 \\
					      0.4 & 0.8
				      \end{bNiceMatrix},\quad
				      x_{0}=
				      \begin{bNiceMatrix}
					      1 \\
					      0
				      \end{bNiceMatrix},\quad
				      \begin{aligned}
					      x_{1} & =
					      Ax_{0}=
					      \begin{bNiceMatrix}
						      0.6 \\
						      0.4
					      \end{bNiceMatrix}\to
					      0.4
					      \begin{bNiceMatrix}
						      1.5 \\
						      1
					      \end{bNiceMatrix} \\
					      x_{2} & =
					      Ax_{1}=
					      \begin{bNiceMatrix}
						      0.44 \\
						      0.56
					      \end{bNiceMatrix}\to
					      0.4
					      \begin{bNiceMatrix}
						      1 \\
						      1.27
					      \end{bNiceMatrix} \\
					      x_{6} & =
					      Ax_{5}=
					      \begin{bNiceMatrix}
						      0.336064 \\
						      0.663936
					      \end{bNiceMatrix}\to
					      0.336064
					      \begin{bNiceMatrix}
						      1 \\
						      1.975623
					      \end{bNiceMatrix}\approx
					      \begin{bNiceMatrix}
						      1 \\
						      2
					      \end{bNiceMatrix}.
				      \end{aligned}
			      \end{equation*}

			      Entonces podemos ver que el vector $x_{6}$ se acerca
			      al autovector dominante de autovalor $1$.
		\end{enumerate}
	\end{solution}
\end{frame}

\begin{frame}
	\begin{solution}
		\begin{enumerate}[d)]
			\item

			      Método de Potencia Escalado
			      \begin{equation*}
				      A=
				      \begin{bNiceMatrix}
					      0.6 & 0.2 \\
					      0.4 & 0.8
				      \end{bNiceMatrix},\quad
				      x_{0}=
				      \begin{bNiceMatrix}
					      1 \\
					      0
				      \end{bNiceMatrix},\quad
				      \begin{aligned}
					      Ax_{0} & =
					      \begin{bNiceMatrix}
						      0.6 \\
						      0.4
					      \end{bNiceMatrix}\to
					      x_{1}=
					      \begin{bNiceMatrix}
						      1 \\
						      0.66
					      \end{bNiceMatrix} \\
					      Ax_{1} & =
					      \begin{bNiceMatrix}
						      0.73 \\
						      0.93
					      \end{bNiceMatrix}\to
					      x_{2}=
					      \begin{bNiceMatrix}
						      0.785 \\
						      1
					      \end{bNiceMatrix} \\
					      Ax_{5} & =
					      \begin{bNiceMatrix}
						      0.73 \\
						      0.93
					      \end{bNiceMatrix}\to
					      x_{6}=
					      \begin{bNiceMatrix}
						      0.506 \\
						      1
					      \end{bNiceMatrix}
				      \end{aligned}
			      \end{equation*}

			      Entonces podemos ver que el vector $x_{6}$ se
			      acerca al autovector dominante de autovalor $1$.
		\end{enumerate}
	\end{solution}
\end{frame}