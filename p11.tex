\section{Pregunta N$^{\circ}$11\qquad Alejandro Escobar Mejia}

\begin{frame}
	\frametitle{Cálculo de la inversa de una matriz grande $A\in\mathbb{R}^{n\times n}$}

	Es una tarea desafiante porque usando la fórmula
	\begin{math}
		\det\left(A\right)=
		\sum_{\sigma}
		\operatorname{sign}\left(\sigma\right)
		a_{1\sigma\left(1\right)}
		\cdots
		a_{n\sigma\left(n\right)}
	\end{math}
	podría requerir $O\left(\left(n-1\right)n!\right)$
	multiplicaciones.
	El algoritmo de eliminación gaussiana permite transformar una
	matriz en forma triangular con $O\left(n^{3}\right)$ operaciones.
	Además, este algoritmo incluye divisiones por entradas de la
	matriz, lo que requiere una estrategia de pivote para evitar
	inestabilidades numéricas.
	Es más, este algoritmo no se puede utilizar sobre matrices que
	tiene entradas sobre un anillo conmutativo sin división.
	Por lo tanto, es deseable encontrar un algoritmo rápido sin
	divisiones.
	El algoritmo clásico de \alert{Faddeev-LeVerrier} proporciona
	precisamente esto, su complejidad computacional es del orden
	$O\left(n^{\beta+1}\right)$ y evita cualquier división por una
	entrada de la matriz.
	Aquí $O\left(n^{\beta}\right)$ es el costo computacional de
	multiplicar dos matrices $n\times n$.
	El valor preciso de $\beta$ es desconocido, pero está en el
	intervalo $\left[2,2.37286\right[$. Este enfoque consiste en
	\begin{equation*}
		B_{0}=I_{n},\quad
		\alpha_{k}=
		\dfrac{1}{k}
		\operatorname{tr}\left(AB_{k-1}\right),\quad
		B_{k}=-AB_{k-1}+\alpha_{k},\quad
		\forall k\in\mathbb{N}.
	\end{equation*}

	\begin{block}{Derivación del algoritmo}
		\begin{equation*}
			\chi\left(t\right)\coloneqq
			\sum\limits_{j=0}^{n}
			c_{n-j}t^{j}
		\end{equation*}
	\end{block}

	\alert{método de Krylov}.
\end{frame}

\begin{frame}
	Sea $A\in\mathbb{R}^{n\times n}$ una matriz y su polinomio
	característico es
	\begin{equation*}
		a\left(\lambda\right)=
		\det\left(\lambda I_{n}-A\right)=
		\lambda^{n}+a_{1}\lambda^{n-1}+\cdots+
		a_{n-1}\lambda^{n}+a_{n},
	\end{equation*}
	donde $I_{n}$ denota la matriz identidad de orden $n$, y sea
	\begin{equation*}
		{\left(\lambda I_{n}-A\right)}^{n-1}=
		\dfrac{
		\lambda^{n-1}I_{n}+
		\lambda^{n-2}B_{1}+
		\cdots+
		\lambda B_{n-2}+
		B_{n-1}
		}{a\left(\lambda\right)}.
	\end{equation*}

	\begin{align*}
		a_{1} & =-\operatorname{tr}\left(A\right),                   &
		a_{k} & =-\frac{1}{k}\operatorname{tr}\left(AB_{k-1}\right),
		      & k\in\left\{2,\dotsc,n\right\}.                         \\
		B_{1} & = A + a_{1}I_{n},                                    &
		B_{k} & =AB_{k-1}+a_{k}I_{n},
		      & k\in\left\{2,\dotsc,n-1\right\}.
	\end{align*}
	donde $\operatorname{tr}\left(A\right)$ denota la traza de $A$.
\end{frame}

\begin{frame}
	\begin{enumerate}\setcounter{enumi}{10}
		\item

		      Un territorio está dividido en dos zonas $Z_{1}$ y
		      $Z_{2}$ entre las que habita una población de aves.
		      Cada año y debido a diversas razones (disponibilidad de
		      alimentos, peleas por el territorio, etc.) se producen
		      las siguientes flujos migratorios entre las distintas
		      zonas.

		      \begin{columns}
			      \begin{column}{0.48\textwidth}
				      \begin{itemize}
					      \item

					            En $Z_{1}$: un $60$\% permanece en $Z_{1}$
					            y un $40$\% migra a $Z_{2}$.
				      \end{itemize}
			      \end{column}
			      \begin{column}{0.48\textwidth}
				      \begin{itemize}
					      \item

					            En $Z_{2}$: un $20$\% migra a $Z_{1}$ y un
					            $80$\% permanece en $Z_{2}$.
				      \end{itemize}
			      \end{column}
		      \end{columns}

		      Supongamos que tenemos una situación inicial en la que la
		      población total de aves un $60$\% viven en $Z_{1}$, un
		      $40$\% viven en $Z_{2}$.

		      \begin{enumerate}[a)]
			      \item

			            Indique las variables a usar.

			      \item

			            Determine la matriz que define la migración.

			      \item

			            Determine el polinomio característico usando los
			            métodos Leverrier y Krylov.

			      \item

			            Determine todos los valores y vectores propios
			            usando los métodos dados en clase.
		      \end{enumerate}
	\end{enumerate}

	\begin{solution}
		\begin{enumerate}[a)]
			\item

			      Sean $x_{1}$ y $x_{2}$ la cantidad de aves en la zona
			      $Z_{1}$ y $Z_{2}$, respectivamente.

			\item

			      \begin{equation*}
				      \begin{aligned}
					      x^{\left(k+1\right)}_{1} & =
					      0.6x^{\left(k\right)}_{1}+
					      0.2x_{2}^{\left(k\right)}    \\
					      x^{\left(k+1\right)}_{2} & =
					      0.4x^{\left(k\right)}_{1}+
					      0.8x^{\left(k\right)}_{2}
				      \end{aligned}\iff
				      \begin{bNiceMatrix}
					      x^{\left(k+1\right)}_{1} \\
					      x^{\left(k+1\right)}_{2}
				      \end{bNiceMatrix}
				      =
				      \begin{bNiceMatrix}
					      0.6 & 0.2 \\
					      0.4 & 0.8
				      \end{bNiceMatrix}
				      \begin{bNiceMatrix}
					      x^{\left(k\right)}_{1} \\
					      x^{\left(k\right)}_{2}
				      \end{bNiceMatrix}\iff
				      x^{\left(k+1\right)}=
				      Ax^{\left(k\right)}.
			      \end{equation*}

			\item

			      Método de Leverrier

			      \begin{equation*}
				      A=\begin{bNiceMatrix}
					      0.6 & 0.2 \\
					      0.4 & 0.8
				      \end{bNiceMatrix},\quad
				      A^{2}=
				      \begin{bNiceMatrix}
					      0.44 & 0.28 \\
					      0.56 & 0.72
				      \end{bNiceMatrix},\quad
				      \begin{aligned}
					      s_{1} & =
					      \operatorname{tr}
					      \left(A\right)=
					      0.6+0.8=
					      1.4.      \\
					      s_{2} & =
					      \operatorname{tr}
					      \left(A^{2}\right)=
					      0.44+0.72=
					      1.16.     \\
					      a_{1} & =
					      -s_{1}=
					      -1.4.     \\
					      a_{2} & =
					      -\frac{1}{2}
					      \left(
					      s_{2}+
					      \left(a_{1}\times s_{1}\right)
					      \right)=
					      -\frac{1}{2}
					      \left(
					      1.16+
					      \left(-1.4\times 1.4\right)
					      \right)=
					      0.4.
				      \end{aligned}
			      \end{equation*}
		\end{enumerate}
	\end{solution}
\end{frame}

\begin{frame}
	\begin{solution}
		\begin{enumerate}[c)]
			\item

			      Así,
			      \begin{math}
				      P\left(x\right)=
				      x^{2}-1.4x+0.4
			      \end{math}.

			      Método de Krylov:

			      \begin{equation*}
				      \begin{aligned}
					      y_{0} & =
					      \begin{bNiceMatrix}
						      1 \\
						      0
					      \end{bNiceMatrix}. \\
					      y_{1} & =
					      Ay_{0}=
					      \begin{bNiceMatrix}
						      0.6 \\
						      0.4
					      \end{bNiceMatrix}. \\
					      y_{2} & =
					      Ay_{1}=
					      \begin{bNiceMatrix}
						      0.44 \\
						      0.56
					      \end{bNiceMatrix}.
				      \end{aligned},\quad
				      \begin{aligned}
					      \begin{bNiceMatrix}
						      y_{1} & y_{0}
					      \end{bNiceMatrix}
					      \begin{bNiceMatrix}
						      a_{1} \\
						      a_{2}
					      \end{bNiceMatrix} & =
					      y_{2}.                \\
					      \begin{bNiceMatrix}
						      0.6 & 1 \\
						      0.4 & 0
					      \end{bNiceMatrix}
					      \begin{bNiceMatrix}
						      a_{1} \\
						      a_{2}
					      \end{bNiceMatrix} & =
					      \begin{bNiceMatrix}
						      0.44 \\
						      0.56
					      \end{bNiceMatrix}.    \\
					      \begin{bNiceMatrix}
						      a_{1} \\
						      a_{2}
					      \end{bNiceMatrix} & =
					      \begin{bNiceMatrix}
						      -1.4 \\
						      0.4
					      \end{bNiceMatrix}.
				      \end{aligned}
			      \end{equation*}

			      Así,
			      \begin{math}
				      P\left(x\right)=
				      x^{2}-1.4x+0.4
			      \end{math}.
		\end{enumerate}

		\begin{enumerate}[d)]
			\item

			      Método de Potencia
			      \begin{equation*}
				      A=
				      \begin{bNiceMatrix}
					      0.6 & 0.2 \\
					      0.4 & 0.8
				      \end{bNiceMatrix},\quad
				      x_{0}=
				      \begin{bNiceMatrix}
					      1 \\
					      0
				      \end{bNiceMatrix},\quad
				      \begin{aligned}
					      x_{1} & =
					      Ax_{0}=
					      \begin{bNiceMatrix}
						      0.6 \\
						      0.4
					      \end{bNiceMatrix}\to
					      0.4
					      \begin{bNiceMatrix}
						      1.5 \\
						      1
					      \end{bNiceMatrix} \\
					      x_{2} & =
					      Ax_{1}=
					      \begin{bNiceMatrix}
						      0.44 \\
						      0.56
					      \end{bNiceMatrix}\to
					      0.4
					      \begin{bNiceMatrix}
						      1 \\
						      1.27
					      \end{bNiceMatrix} \\
					      x_{6} & =
					      Ax_{5}=
					      \begin{bNiceMatrix}
						      0.336064 \\
						      0.663936
					      \end{bNiceMatrix}\to
					      0.336064
					      \begin{bNiceMatrix}
						      1 \\
						      1.975623
					      \end{bNiceMatrix}\approx
					      \begin{bNiceMatrix}
						      1 \\
						      2
					      \end{bNiceMatrix}.
				      \end{aligned}
			      \end{equation*}

			      Entonces podemos ver que el vector $x_{6}$ se acerca
			      al autovector dominante de autovalor $1$.
		\end{enumerate}
	\end{solution}
\end{frame}

\begin{frame}
	\begin{solution}
		\begin{enumerate}[d)]
			\item

			      Método de Potencia Escalado
			      \begin{equation*}
				      A=
				      \begin{bNiceMatrix}
					      0.6 & 0.2 \\
					      0.4 & 0.8
				      \end{bNiceMatrix},\quad
				      x_{0}=
				      \begin{bNiceMatrix}
					      1 \\
					      0
				      \end{bNiceMatrix},\quad
				      \begin{aligned}
					      Ax_{0} & =
					      \begin{bNiceMatrix}
						      0.6 \\
						      0.4
					      \end{bNiceMatrix}\to
					      x_{1}=
					      \begin{bNiceMatrix}
						      1 \\
						      0.66
					      \end{bNiceMatrix} \\
					      Ax_{1} & =
					      \begin{bNiceMatrix}
						      0.73 \\
						      0.93
					      \end{bNiceMatrix}\to
					      x_{2}=
					      \begin{bNiceMatrix}
						      0.785 \\
						      1
					      \end{bNiceMatrix} \\
					      Ax_{5} & =
					      \begin{bNiceMatrix}
						      0.73 \\
						      0.93
					      \end{bNiceMatrix}\to
					      x_{6}=
					      \begin{bNiceMatrix}
						      0.506 \\
						      1
					      \end{bNiceMatrix}
				      \end{aligned}
			      \end{equation*}

			      Entonces podemos ver que el vector $x_{6}$ se
			      acerca al autovector dominante de autovalor $1$.
		\end{enumerate}
	\end{solution}
\end{frame}